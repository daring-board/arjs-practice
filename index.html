<!DOCTYPE html>
<html>
  <script src="https://aframe.io/releases/1.0.4/aframe.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js"> </script> 
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/handpose"></script> 

  <body style="margin : 0px; overflow: hidden;">
    <a-scene>
      <a-box position="-1 0.5 -3" rotation="0 45 0" color="#4CC3D9"></a-box>
      <a-sphere position="0 1.25 -5" radius="1.25" color="#EF2D5E"></a-sphere>
      <a-cylinder position="1 0.75 -3" radius="0.5" height="1.5" color="#FFC65D"></a-cylinder>
      <a-plane position="0 0 -4" rotation="-90 0 0" width="4" height="4" color="#7BC8A4"></a-plane>
      <a-sky color="#ECECEC"></a-sky>

      <a-assets>
        <video id="myVideo" width="400" height="300" autoplay="1" crossorigin="anonymous"></video>
      </a-assets>
      <a-video src="#myVideo" width="16" height="9" position="0 10 -20"></a-video>
    </a-scene>
  </body>
</html>

<script>
const _sleep = (ms) => new Promise((resolve) => setTimeout(resolve, ms));

var video = document.getElementById('myVideo');
var localStream = null;
if(navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
  navigator.mediaDevices.getUserMedia({ video: {facingMode: "user"} }).then(stream => {
    video.srcObject = stream;
  })
}

video.addEventListener('loadeddata', (event) => {
  main(event.srcElement)
})

async function main(video){
  const model = await handpose.load();
  while(true) {
    console.log('estimate!!');
    const predict = await model.estimateHands(video);
    console.log(predict)

    // if (predict.length > 0) {
    //   for (let i = 0; i < predict.length; i++) {
    //     const keypoints = predict[i].landmarks;

    //     // Log hand keypoints.
    //     for (let i = 0; i < keypoints.length; i++) {
    //       const [x, y, z] = keypoints[i];
    //       console.log(`Keypoint ${i}: [${x}, ${y}, ${z}]`);
    //     }
    //   }
    // }
  }
}
</script>